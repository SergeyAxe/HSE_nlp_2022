{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wTjLOlc8ib0"
   },
   "source": [
    "<h1><center>Простые векторные модели текста</center></h1>\n",
    "\n",
    "<img src=\"pipeline_vec.png\" alt=\"pipeline.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Задача: классификация твитов по тональности\n",
    "\n",
    "В этом занятии мы познакомимся с распространенной задачей в анализе текстов: с классификацией текстов на классы.\n",
    "\n",
    "В рассмотренном тут примере классов будет два: положительный и отрицательный, такую постановку этой задачи обычно называют классификацией по тональности или sentiment analysis.\n",
    "\n",
    "Классификацию по тональности используют, например, в рекомендательных системах и при анализе отзывов клиентов, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Более подробно мы рассмотрим данную задачу и познакомимся с более сложными методами её решения в семинаре 3, а здесь разберем простые подходы, основанные на методе мешка слов.\n",
    "\n",
    "У нас есть [данные постов в твиттере](http://study.mokoron.com/), про из которых каждый указано, как он эмоционально окрашен: положительно или отрицательно. \n",
    "\n",
    "**Задача**: построить модель, которая по тексту поста предсказывает его эмоциональную окраску.\n",
    "\n",
    "\n",
    "Скачиваем данные: [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuDVGp4O8ib1",
    "outputId": "11001569-4329-4c75-f8f0-2c5ec63708b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-12 16:38:20--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2022-09-12 16:38:21--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com/cd/0/inline/Bsy5KzJN9lQQ0XA5rrdeBDNyNeubQa7hzNvTXtCD5IFEK_4suXN6f8R-_T-TcqJId3gQn1604i1JENpO6Wo45p2_RzuFXFaiL_hKMuXMeXe8MxkfJcb0__hzpkqav94l544z8zR30irb8cBE63c58UCh-acR2MNdM0Wx7s6s1_RIzw/file# [following]\n",
      "--2022-09-12 16:38:22--  https://uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com/cd/0/inline/Bsy5KzJN9lQQ0XA5rrdeBDNyNeubQa7hzNvTXtCD5IFEK_4suXN6f8R-_T-TcqJId3gQn1604i1JENpO6Wo45p2_RzuFXFaiL_hKMuXMeXe8MxkfJcb0__hzpkqav94l544z8zR30irb8cBE63c58UCh-acR2MNdM0Wx7s6s1_RIzw/file\n",
      "Resolving uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com (uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com)... 162.125.71.15\n",
      "Connecting to uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com (uc5a7eee673483b937e76fb66523.dl.dropboxusercontent.com)|162.125.71.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25,02M  8,51MB/s    in 2,9s    \n",
      "\n",
      "2022-09-12 16:38:25 (8,51 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2022-09-12 16:38:25--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2022-09-12 16:38:26--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com/cd/0/inline/BsxJJ1xRxc6TzQHwzJeRxePTe3xDT1THDDIU_-o7fCrTc8kmCaOod95JFlX_RU3bW-lo76J_Yx-EFK_3LyrrwbGFzGVlHBubu4TUCeRd3JsCd3KVbRCekEWyi_QRkjc43FLCBE7B3-gt7L-WBnmCA5TMDTiRnbHf35xjdP0k7MahjQ/file# [following]\n",
      "--2022-09-12 16:38:26--  https://uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com/cd/0/inline/BsxJJ1xRxc6TzQHwzJeRxePTe3xDT1THDDIU_-o7fCrTc8kmCaOod95JFlX_RU3bW-lo76J_Yx-EFK_3LyrrwbGFzGVlHBubu4TUCeRd3JsCd3KVbRCekEWyi_QRkjc43FLCBE7B3-gt7L-WBnmCA5TMDTiRnbHf35xjdP0k7MahjQ/file\n",
      "Resolving uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com (uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com)... 162.125.71.15\n",
      "Connecting to uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com (uc0e188200952cd7fca49de7889c.dl.dropboxusercontent.com)|162.125.71.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23,32M  7,82MB/s    in 3,0s    \n",
      "\n",
      "2022-09-12 16:38:30 (7,82 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPp8_2Sy8ib5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsmSQOE98ib8"
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv('./positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('./negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc9rKWk8ib-",
    "outputId": "ad6faf65-5361-434d-a46d-a7c176603a14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71243</th>\n",
       "      <td>То чувство, когда у тебя не работает ВК и ты никак не можешь поздравить остальных своих друзей ;(\\n#НГ  #пздц</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31533</th>\n",
       "      <td>По ТНТ идёт полицейская академия. Ностальгия :(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81528</th>\n",
       "      <td>Мой телефон реагирует на отмерзшие пальцы в перчатках, правда писать не очень удобно:|</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109614</th>\n",
       "      <td>@_Angel_OF_Lord А ПОЧЕМУ ВОКРУГ СТОЛА?\\nПРОСТО МОЯ БОЛЬНАЯ ФАНТАЗИЯ УЖЕ СТРОИТ НЕ ОЧЕНЬ ПРИЛИЧНЫЕ КАРТИНКИ В УМЕ:DD #жаркийчетверг</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109132</th>\n",
       "      <td>-Вы расстались, из-за чего? \\n-Да если бы я сам это знал(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      text     label\n",
       "71243                        То чувство, когда у тебя не работает ВК и ты никак не можешь поздравить остальных своих друзей ;(\\n#НГ  #пздц  negative\n",
       "31533                                                                                      По ТНТ идёт полицейская академия. Ностальгия :(  negative\n",
       "81528                                               Мой телефон реагирует на отмерзшие пальцы в перчатках, правда писать не очень удобно:|  negative\n",
       "109614  @_Angel_OF_Lord А ПОЧЕМУ ВОКРУГ СТОЛА?\\nПРОСТО МОЯ БОЛЬНАЯ ФАНТАЗИЯ УЖЕ СТРОИТ НЕ ОЧЕНЬ ПРИЛИЧНЫЕ КАРТИНКИ В УМЕ:DD #жаркийчетверг  positive\n",
       "109132                                                                           -Вы расстались, из-за чего? \\n-Да если бы я сам это знал(  negative"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся функцией для предобработки текста, которую мы написали в прошлом семинаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226834/226834 [00:54<00:00, 4168.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75734</th>\n",
       "      <td>мне мало мало мало мне малооо зарядки на плеере:(</td>\n",
       "      <td>negative</td>\n",
       "      <td>мало мало мало малооо зарядка плеер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22310</th>\n",
       "      <td>@ehnevermind Я никогда его не найду &amp;gt;;(</td>\n",
       "      <td>negative</td>\n",
       "      <td>ehnevermind найти</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73725</th>\n",
       "      <td>RT @igajaqytmu: смотрит на вас, как на вебкамеру. И странно скалится при этом %))</td>\n",
       "      <td>positive</td>\n",
       "      <td>igajaqytmu смотреть вебкамера странно скалиться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16467</th>\n",
       "      <td>всё вернулось на свои места))\\nопять в чс\\nя счастлив\\nтварь</td>\n",
       "      <td>positive</td>\n",
       "      <td>вернуться свой место счастливый тварь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>@funkyboyakeem я не пила мандариновую водку) и с возрастом не угадал</td>\n",
       "      <td>positive</td>\n",
       "      <td>funkyboyakeem пила мандариновый водка возраст угадать</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    text     label                                                 lemmas\n",
       "75734                                  мне мало мало мало мне малооо зарядки на плеере:(  negative                    мало мало мало малооо зарядка плеер\n",
       "22310                                         @ehnevermind Я никогда его не найду &gt;;(  negative                                      ehnevermind найти\n",
       "73725  RT @igajaqytmu: смотрит на вас, как на вебкамеру. И странно скалится при этом %))  positive        igajaqytmu смотреть вебкамера странно скалиться\n",
       "16467                       всё вернулось на свои места))\\nопять в чс\\nя счастлив\\nтварь  positive                  вернуться свой место счастливый тварь\n",
       "9758                @funkyboyakeem я не пила мандариновую водку) и с возрастом не угадал  positive  funkyboyakeem пила мандариновый водка возраст угадать"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "with Pool(4) as p:\n",
    "    lemmas = list(tqdm(p.imap(clean_text, df['text']), total=len(df)))\n",
    "    \n",
    "df['lemmas'] = lemmas\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на train и test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3MD0bex8icC"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.lemmas, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ppAtTFc8icE"
   },
   "source": [
    "## Мешок слов (Bag of Words, BoW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gJLFKQ38icE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AMGIJ8C8icH"
   },
   "source": [
    "... Но сперва пару слов об n-граммах. Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0-y2A6k8icH"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_lgEYzY8icJ",
    "outputId": "f9d482bd-0c45-4830-9e7b-1b49d1290468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Факультет',),\n",
       " ('компьютерных',),\n",
       " ('наук',),\n",
       " ('Высшей',),\n",
       " ('школы',),\n",
       " ('экономики',)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Факультет компьютерных наук Высшей школы экономики'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDRi-68C8icM",
    "outputId": "8d04b779-f404-4c5e-e06c-125ef4f4572d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Факультет', 'компьютерных'),\n",
       " ('компьютерных', 'наук'),\n",
       " ('наук', 'Высшей'),\n",
       " ('Высшей', 'школы'),\n",
       " ('школы', 'экономики')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaUeKBDh8icO",
    "outputId": "831fbc23-1c08-4b7b-e5fd-856c10132bdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Факультет', 'компьютерных', 'наук'),\n",
       " ('компьютерных', 'наук', 'Высшей'),\n",
       " ('наук', 'Высшей', 'школы'),\n",
       " ('Высшей', 'школы', 'экономики')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z325_XfX8icS",
    "outputId": "5da7999f-0cf3-4964-8d23-e958f21d5f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Факультет', 'компьютерных', 'наук', 'Высшей', 'школы'),\n",
       " ('компьютерных', 'наук', 'Высшей', 'школы', 'экономики')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80h0e8FJ8icV"
   },
   "source": [
    "Итак, мы хотим преобразовать наши обработанные данные в вектора с помощью мешка слов. Мешок слов можно строить как для отдельных слов (лемм в нашем случае), так и для n-грамм, и это может улучшать качество. \n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SQaMJbl8icW"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1)) # строим BoW для слов\n",
    "bow = vec.fit_transform(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6eZOyAf8icY"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве признаков:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: соответствие слов и их индексов в словаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8cncS9M8icY",
    "outputId": "c1943f5c-3400-4fb1-d218-c8f89d225634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('жаль', 110128),\n",
       " ('стать', 153946),\n",
       " ('редко', 147080),\n",
       " ('заходить', 112987),\n",
       " ('новогодний', 130623),\n",
       " ('каникулы', 116354),\n",
       " ('пролететь', 144046),\n",
       " ('день', 106675),\n",
       " ('заметить', 112070),\n",
       " ('успеть', 160401)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x169048 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть вектора, на которых можно обучать модели! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Rq60E68ica",
    "outputId": "5caa0b70-3a96-4efb-f241-93120aa9f362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aksenov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество классификации на тестовой выборке. Для этого выведем classification_report из модуля [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n",
    "В качестве целевой метрики качества будем рассматривать macro average f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xf8gqHSD8icc",
    "outputId": "71a8da2f-d5c6-4070-b28e-d99cc7145832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.74     28385\n",
      "    positive       0.73      0.75      0.74     28324\n",
      "\n",
      "    accuracy                           0.74     56709\n",
      "   macro avg       0.74      0.74      0.74     56709\n",
      "weighted avg       0.74      0.74      0.74     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdoG6YCr8icf"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GUDAWcz8icg",
    "outputId": "88bfc3b3-7eb9-4082-f500-84d75c2e3d68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aksenov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.53      0.68     51252\n",
      "    positive       0.16      0.84      0.27      5457\n",
      "\n",
      "    accuracy                           0.56     56709\n",
      "   macro avg       0.56      0.69      0.48     56709\n",
      "weighted avg       0.89      0.56      0.64     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество существенно хуже. Ниже мы поймем, почему это так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4PTszK9h8ick"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ9Td4bw8icm"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Ключевая идея этого подхода – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8B_Q8qP8icm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn-S--vi8ico",
    "outputId": "42455755-3c0c-4ab2-c08d-caf318cad0d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aksenov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.74      0.72     26327\n",
      "    positive       0.77      0.72      0.74     30382\n",
      "\n",
      "    accuracy                           0.73     56709\n",
      "   macro avg       0.73      0.73      0.73     56709\n",
      "weighted avg       0.74      0.73      0.73     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 500)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXglD7lb8icq"
   },
   "source": [
    "В этот раз получилось хуже, чем с помощью простого CountVectorizer, то есть использование tf-idf не дало улучшений в качестве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETq8X_Tb8idz"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Иногда в ходе стандартного препроцессинга теряются важные признаки. Посмотрим, что будет если не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52766</th>\n",
       "      <td>RT @tataholiday: хочу вернуть старые времена, опять :( \\n#miss</td>\n",
       "      <td>negative</td>\n",
       "      <td>tataholiday хотеть вернуть старое время miss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text     label                                        lemmas\n",
       "52766  RT @tataholiday: хочу вернуть старые времена, опять :( \\n#miss  negative  tataholiday хотеть вернуть старое время miss"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>new_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24694</th>\n",
       "      <td>Q: подпишись\\nпожалуйста*)  A: http://t.co/XKTaDVlUP2</td>\n",
       "      <td>positive</td>\n",
       "      <td>подписаться пожалуйста http xktadvlup</td>\n",
       "      <td>q: подпишись\\nпожалуйста*)  a: http://t.co/xktadvlup2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54857</th>\n",
       "      <td>В свои 11 лет, я встречалась с 18-и летним парнем. Мне так жалко таких парней, их друзья оказывается так издеваются. Мы встречались 2 года((</td>\n",
       "      <td>negative</td>\n",
       "      <td>свой встречаться летний парень жалко парный друг оказываться издеваться встречаться</td>\n",
       "      <td>в свои 11 лет, я встречалась с 18-и летним парнем. мне так жалко таких парней, их друзья оказывается так издеваются. мы встречались 2 года((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>Общажный движ закончился тем что все спят, а я нихуя:)</td>\n",
       "      <td>positive</td>\n",
       "      <td>общажный движ закончиться весь спать нихуй</td>\n",
       "      <td>общажный движ закончился тем что все спят, а я нихуя:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text     label                                                                               lemmas                                                                                                                                    new_lemmas\n",
       "24694                                                                                         Q: подпишись\\nпожалуйста*)  A: http://t.co/XKTaDVlUP2  positive                                                подписаться пожалуйста http xktadvlup                                                                                         q: подпишись\\nпожалуйста*)  a: http://t.co/xktadvlup2\n",
       "54857  В свои 11 лет, я встречалась с 18-и летним парнем. Мне так жалко таких парней, их друзья оказывается так издеваются. Мы встречались 2 года((  negative  свой встречаться летний парень жалко парный друг оказываться издеваться встречаться  в свои 11 лет, я встречалась с 18-и летним парнем. мне так жалко таких парней, их друзья оказывается так издеваются. мы встречались 2 года((\n",
       "7777                                                                                         Общажный движ закончился тем что все спят, а я нихуя:)  positive                                           общажный движ закончиться весь спать нихуй                                                                                        общажный движ закончился тем что все спят, а я нихуя:)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_lemmas'] = df.text.apply(lambda x: x.lower())\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.new_lemmas, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ue0DUsX18id0",
    "outputId": "f3858c1f-554f-4f18-8cc4-6fa5416702ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aksenov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27863\n",
      "    positive       1.00      1.00      1.00     28846\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wymeD7-B8id3"
   },
   "source": [
    "Как можно видеть, если оставить пунктуацию, то все метрики равны 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266706, 266706)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.vocabulary_), len(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGKuAvYR8id3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@', 0.1471878855818156)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = list(zip(vec.vocabulary_, clf.coef_[0]))\n",
    "importances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('что', 58.77436936506602),\n",
       " ('//t.co/cuphpysvcp', 27.295181101473574),\n",
       " ('у', 12.578240551762557),\n",
       " ('daromand77', 10.80497075752631),\n",
       " ('кюхенио', 9.111201609919437),\n",
       " ('учете', 8.102007005355661),\n",
       " ('50', 7.678739507821211),\n",
       " ('него', 5.254932152879905),\n",
       " ('коллега', 4.744012822521124),\n",
       " ('останавливало', 4.679962041879572)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importances = sorted(importances, key = lambda x: -x[1])\n",
    "sorted_importances[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QxmioaZ8id8"
   },
   "source": [
    "Посмотрим, как один из наиболее значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17LPHPGR8id9",
    "outputId": "50c87666-43d1-401e-fef9-c19d4faa5e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32901\n",
      "    positive       0.83      1.00      0.90     23808\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.92      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что это уже позволяет достаточно хорошо классифицировать тексты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7VjSCog8id_"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве признаком используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSO-k4wA8id_",
    "outputId": "29b7529b-d86c-466a-802d-186284782503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aksenov/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99     27773\n",
      "    positive       1.00      0.99      1.00     28936\n",
      "\n",
      "    accuracy                           0.99     56709\n",
      "   macro avg       0.99      0.99      0.99     56709\n",
      "weighted avg       0.99      0.99      0.99     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i6JwqL-8ieE"
   },
   "source": [
    "Таким образом, становится понятно, почему на этих данных качество классификации 1. Так или иначе, на символах классифицировать тоже можно.\n",
    "\n",
    "Ещё одна замечательная особенность символьных признаков: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    " На этом занятии мы\n",
    "* познакомились с задачей бинарной классификации текстов.\n",
    "\n",
    "* научились строить простые признаки на основе метода \"мешка слов\" с помощью библиотеки sklearn: CountVectorizer и TfidfVectorizer.\n",
    "\n",
    "* использовали для классификации линейную модель логистической регрессии.\n",
    "\n",
    "* поняли, что многое зависит от подхода к предобработки текста и от признаков, которые используются в модели.\n",
    "\n",
    "* увидели, что в некоторых задачах важно использование каждого символа из текста, в том числе пунктуации.\n",
    "\n",
    "На следующих занятиях мы рассмотрим более сложные модели построения признаков и классификации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
